{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np # linear algebra\n",
    "import os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection  import  train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# personal imports\n",
    "import data_extractor\n",
    "from encoder_categorical_numerical import Encoder_Categorical_Numerical\n",
    "import accuracy_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = False\n",
    "index_beginning_actions = 4\n",
    "upper_limit_seconds = 300\n",
    "lower_limit_seconds = 5\n",
    "\n",
    "training_file = \"./input/TRAIN.CSV\" if not validation else \"./input/minitrain.csv\"\n",
    "validation_file = \"./input/minitest.csv\"\n",
    "#validation_file\n",
    "testing_file = \"./input/TEST.CSV\" if not validation else \"./input/minitest.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer le temps moyen d'une partie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __ceil_to_five__(seconds):\n",
    "    \"\"\"Approximates the number of seconds to the upper multiple of 5.\n",
    "    :param seconds: number of seconds to approximate\n",
    "    :return: approxilated seconds\n",
    "    \"\"\"\n",
    "    modulo = seconds % 5\n",
    "    if modulo == 0:\n",
    "        return seconds\n",
    "    else:\n",
    "        return seconds - modulo + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __remove_tX__(row):\n",
    "    \"\"\"Get a new list of words with words of type tX (X a number) removed\n",
    "    :param myrow: a list of words\"\"\"\n",
    "    tX = re.compile(\"t\\d\")\n",
    "    new_row = []\n",
    "    for cell in row:\n",
    "        if tX.match(cell):\n",
    "            pass\n",
    "        else:\n",
    "            new_row.append(cell)\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_maximum_time_match__(row, default_time=0):\n",
    "    \"\"\"Get the approximate time of a match\n",
    "    :param myrow: one match\"\"\"\n",
    "    tX = re.compile(\"t\\d\")\n",
    "    for cell in row[::-1]:\n",
    "        if tX.match(cell):\n",
    "            return int(cell[1:])\n",
    "    return default_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"t5\", \"a\",\"b\",\"c\", \"t18\",\"a\",\"b\",\"c\", \"t150\", \"a\",\"b\"]\n",
    "__get_maximum_time_match__(a, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer le temps moyen entre deux actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_speed__(row, max_time):\n",
    "    tX = re.compile(\"t\\d\")\n",
    "    nb_actions = len(row)\n",
    "    for cell in row:\n",
    "        if tX.match(cell):\n",
    "            nb_actions = nb_actions-1\n",
    "    return max_time/nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"t5\", \"a\",\"b\",\"c\", \"t18\",\"a\",\"b\",\"c\", \"t150\", \"a\",\"b\"]\n",
    "__get_speed__(a, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConnaÃ®tre toutes les actions possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __recognise_possible_actions__(set_of_actions, row):\n",
    "    for cell in row[index_beginning_actions:]:\n",
    "        set_of_actions.add(cell)\n",
    "    return set_of_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(path_file, training, upper_limit_seconds, lower_limit_seconds):\n",
    "    \"\"\"\n",
    "    :param path_file:\n",
    "    :param training: boolean\n",
    "    :param limit_seconds: int\n",
    "    :return: A DataFrame with columns named id_player, played_race, 0... n, with n the number of kept actions.\n",
    "    \"\"\"\n",
    "    upper_limit_seconds = __ceil_to_five__(upper_limit_seconds)\n",
    "    upper_stop_word = \"t\" + str(upper_limit_seconds)\n",
    "    lower_limit_seconds = __ceil_to_five__(lower_limit_seconds)\n",
    "    lower_stop_word = \"t\" + str(lower_limit_seconds)\n",
    "    \n",
    "    extracted = []\n",
    "    largest_column_count = 0\n",
    "    possible_actions = set()\n",
    "    index_new_feature = 2 if training else 1\n",
    "    lower_column_to_keep = []\n",
    "\n",
    "    # Loop the data lines\n",
    "    with open(path_file) as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter='\\n')\n",
    "        for row in spamreader:\n",
    "            myrow = row[0].split(',')\n",
    "            try:\n",
    "                upper_stop_index = myrow.index(upper_stop_word)\n",
    "            except:\n",
    "                upper_stop_index = -1\n",
    "            try:\n",
    "                lower_stop_index = myrow.index(lower_stop_word)\n",
    "            except:\n",
    "                lower_stop_index = -1\n",
    "            #compute the time of a match and the average speed between two actions\n",
    "            time_match = __get_maximum_time_match__(myrow)\n",
    "            average_speed_match = __get_speed__(myrow, time_match)\n",
    "            #compute the number of columns to keep for ordered actions\n",
    "            lower_column_to_keep.append(len(__remove_tX__(myrow[index_new_feature:lower_stop_index]))-1)\n",
    "            #delete useless tX\n",
    "            myrow = __remove_tX__(myrow[0:upper_stop_index])\n",
    "            #know possible set of actions\n",
    "            possible_actions = __recognise_possible_actions__(possible_actions, myrow)\n",
    "            #compute the average speed between two actions for a specifical time lapse\n",
    "            #average_speed_limited_time = __get_speed__(myrow, limit_seconds)\n",
    "            #insert time_match and average_speed_match as features\n",
    "            myrow.insert(index_new_feature, time_match)\n",
    "            myrow.insert(index_new_feature+1, average_speed_match)         \n",
    "            #myrow.insert(index_time_match+2, average_speed_limited_time)\n",
    "            #count the number of columns\n",
    "            largest_column_count = max(len(myrow), largest_column_count)\n",
    "            extracted.append(myrow)\n",
    "    column_names = []\n",
    "    if training:\n",
    "        column_names = [\"id_player\", \"played_race\", \"time_match\", \"average_speed_match\"] + [(str(i)+\"th_action\") for i in range(0, largest_column_count - index_beginning_actions)]\n",
    "    else:\n",
    "        column_names = [\"played_race\", \"time_match\", \"average_speed_match\"] + [(str(i)+\"th_action\") for i in range(0, largest_column_count - index_beginning_actions+1)]\n",
    "    return pd.DataFrame(extracted, columns = column_names), possible_actions, lower_column_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training, possible_actions_training, lower_column_to_keep_training = get_dataframe(training_file, training=True, upper_limit_seconds=upper_limit_seconds, lower_limit_seconds=lower_limit_seconds)\n",
    "#df_testing, possible_actions_testing, lower_column_to_keep_testing = get_dataframe(testing_file, training=validation, upper_limit_seconds=upper_limit_seconds, lower_limit_seconds=lower_limit_seconds)\n",
    "#possible_actions = list(possible_actions_training.union(possible_actions_testing))\n",
    "possible_actions = possible_actions_training\n",
    "index_column_to_delete = max(lower_column_to_keep_training)+index_beginning_actions+1\n",
    "#index_column_to_delete = max((max(lower_column_to_keep_training)+index_beginning_actions), (max(lower_column_to_keep_testing)+index_beginning_actions-1))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_column_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.head()\n",
    "#df_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT TO DO: Aligner le nombre de colonnes pour training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = (set(df_training.columns) - set(df_testing.columns))-set([\"id_player\"])\n",
    "for column in columns_to_add: \n",
    "    df_testing[column] = np.nan\n",
    "if validation:\n",
    "    training_columns_l = len(df_training.columns)-1\n",
    "    testing_columns_l = len(df_testing.columns)\n",
    "    if testing_columns_l>training_columns_l:\n",
    "        columns_to_add = (set(df_testing.columns) - set(df_training.columns))-set([\"id_player\"])\n",
    "        for column in columns_to_add: \n",
    "            df_training[column] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last index for ordered_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_end_actions = len(df_training.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_end_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculer l'occurence de chaque action pendant une durÃ©e donnÃ©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __row_of_occurence_actions__(actions, counts, list_of_all_actions):\n",
    "    dict_of_occurence = {action: 0 for action in list_of_all_actions}\n",
    "    for action, count in zip(actions, counts):\n",
    "        dict_of_occurence[action] = count   \n",
    "    return [int(dict_of_occurence[action]) for action in list_of_all_actions]\n",
    "        \n",
    "def __compute_occurence_actions__(df, list_of_all_actions, training=True):\n",
    "    df_occurence_actions = pd.DataFrame(0, index=df.index, columns=list_of_all_actions, dtype=int)\n",
    "    for index, row in df.iterrows():\n",
    "        column_index_start = index_beginning_actions if training else index_beginning_actions-1\n",
    "        row_to_examine = df.iloc[index,column_index_start:]\n",
    "        actions, counts = np.unique(row_to_examine.dropna().values, return_counts=True)\n",
    "        df_occurence_actions.iloc[index,] = __row_of_occurence_actions__(actions, counts, list_of_all_actions)\n",
    "    return df.join(df_occurence_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = __compute_occurence_actions__(df_training, possible_actions)\n",
    "#df_testing = __compute_occurence_actions__(df_testing, possible_actions, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete colums to have lower ordered actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __delete_columns_for_lower_limit__(df, begin_index, end_index):\n",
    "    columns_to_delete = list(df.columns[begin_index:end_index])\n",
    "    return df.drop(columns_to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we want to delete everything as ordonnancy of actions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_column_to_delete = index_beginning_actions+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = __delete_columns_for_lower_limit__(df_training, index_column_to_delete, index_end_actions)\n",
    "#df_testing = __delete_columns_for_lower_limit__(df_testing, index_column_to_delete, index_end_actions)\n",
    "index_end_actions = index_column_to_delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encodage\n",
    "encoder = Encoder_Categorical_Numerical(df_training, index_beginning_actions, index_end_actions)\n",
    "df_encoded_training = encoder.encode_df(df_training)\n",
    "#df_encoded_testing = encoder.encode_df(df_testing, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_training.head()\n",
    "#df_encoded_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ordered actions, fill with -1 after lower time limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_training = df_encoded_training.fillna(-1)\n",
    "#df_encoded_testing = df_encoded_testing.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __remove_values_to_agree_lower_limit__(df, training, lower_limit_colums, end_index):\n",
    "    for index_row, begin_index_column in enumerate(lower_limit_colums):\n",
    "        begin_index_column = begin_index_column + index_beginning_actions\n",
    "        if training:\n",
    "            begin_index_column += 1\n",
    "        df.iloc[index_row, begin_index_column:end_index] = -1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_training = __remove_values_to_agree_lower_limit__(df_encoded_training, True, lower_column_to_keep_training, index_end_actions)\n",
    "#df_encoded_testing = __remove_values_to_agree_lower_limit__(df_encoded_testing, validation, lower_column_to_keep_testing, index_end_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_training.head()\n",
    "#df_encoded_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "scores_saved = dict()\n",
    "for j in [2000,6000, 8000]:\n",
    "    clf_stump=RandomForestClassifier(max_features=None,max_leaf_nodes=j)\n",
    "    for i in range(20, 80, 10):\n",
    "        baglfy=BaggingClassifier(base_estimator=clf_stump,n_estimators=i,\n",
    "            max_samples=1.0)\n",
    "        scores = cross_val_score(baglfy, df_encoded_training.iloc[:, 1:].values, y=df_encoded_training.id_player.values, cv=k)\n",
    "        scores_saved[str(j)+\"max_leaf\"+str(i)] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 64, max_depth = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.fit(df_encoded_training.iloc[:, 1:].values, df_encoded_training.id_player.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = decision_tree.predict(df_encoded_testing.values)\n",
    "decoded_predicted = encoder.decode_labels(predicted)  # We decode the encoded predictions\n",
    "indices = range(1, len(predicted) + 1)\n",
    "output_df = pd.DataFrame({\"RowId\": indices, \"prediction\": decoded_predicted})\n",
    "output_df.to_csv(\"test_labels.CSV\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nolabel_df_validation = df_encoded_testing.drop(axis=1, labels=\"id_player\")\n",
    "nolabel_df_validation.fillna(0)\n",
    "predicted = decision_tree.predict(nolabel_df_validation.values)\n",
    "labels = df_encoded_testing.id_player.values\n",
    "print(\"accuracy:\", accuracy_extractor.get_accuracy(labels, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "scores = cross_val_score(model, df_encoded_training.iloc[:, 1:].values, y=df_encoded_training.id_player.values, cv=k)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
